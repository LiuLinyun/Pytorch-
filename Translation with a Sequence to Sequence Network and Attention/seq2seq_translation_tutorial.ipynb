{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Translation with a Sequence to Sequence Network and Attention\n",
    "=================================\n",
    "*************************************************************\n",
    "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
    "\n",
    "In this project we will be teaching a neural network to translate from\n",
    "French to English.  \n",
    "在这个项目中，我们将训练一个神经网络去把法语翻译成英语。\n",
    "\n",
    "::\n",
    "\n",
    "    [KEY: > input, = target, < output]  \n",
    "    [关键字： > 输入， = 目标， < 输出]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone .\n",
    "\n",
    "... to varying degrees of success.\n",
    "\n",
    "This is made possible by the simple but powerful idea of the [sequence\n",
    "to sequence network](http://arxiv.org/abs/1409.3215), in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a vector,\n",
    "and a decoder network unfolds that vector into a new sequence.  \n",
    "“序列到序列网络” 这个简单却有用的想法使得这变为可能。 其中使用两个RNN把一个序列转换到另一个序列。\n",
    "一个编码器网络把一个输入压缩成一个向量，另一个解码器网络展开这个向量成一个新的序列。\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/seq2seq.png)\n",
    "\n",
    "To improve upon this model we'll use an [attention\n",
    "mechanism](https://arxiv.org/abs/1409.0473), which lets the decoder\n",
    "learn to focus over a specific range of the input sequence.  \n",
    "为改进模型，我们将使用“注意力机制”， 它使解码器注意特定范围的输入序列。\n",
    "\n",
    "**Recommended Reading:**\n",
    "\n",
    "I assume you have at least installed PyTorch, know Python, and\n",
    "understand Tensors:\n",
    "\n",
    "-  http://pytorch.org/ For installation instructions\n",
    "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
    "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
    "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
    "\n",
    "\n",
    "It would also be useful to know about Sequence to Sequence networks and\n",
    "how they work:\n",
    "\n",
    "-  [Learning Phrase Representations using RNN Encoder-Decoder for\n",
    "   Statistical Machine Translation](http://arxiv.org/abs/1406.1078)\n",
    "-  [Sequence to Sequence Learning with Neural\n",
    "   Networks](http://arxiv.org/abs/1409.3215)\n",
    "-  [Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate](https://arxiv.org/abs/1409.0473)\n",
    "-  [A Neural Conversational Model](http://arxiv.org/abs/1506.05869)\n",
    "\n",
    "You will also find the previous tutorials on\n",
    ":doc:`/intermediate/char_rnn_classification_tutorial`\n",
    "and :doc:`/intermediate/char_rnn_generation_tutorial`\n",
    "helpful as those concepts are very similar to the Encoder and Decoder\n",
    "models, respectively.\n",
    "\n",
    "And for more, read the papers that introduced these topics:\n",
    "\n",
    "-  [Learning Phrase Representations using RNN Encoder-Decoder for\n",
    "   Statistical Machine Translation](http://arxiv.org/abs/1406.1078)\n",
    "-  [Sequence to Sequence Learning with Neural\n",
    "   Networks](http://arxiv.org/abs/1409.3215)\n",
    "-  [Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate](https://arxiv.org/abs/1409.0473)\n",
    "-  [A Neural Conversational Model](http://arxiv.org/abs/1506.05869)\n",
    "\n",
    "\n",
    "**Requirements**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data files  加载数据文件\n",
    "==================\n",
    "\n",
    "The data for this project is a set of many thousands of English to\n",
    "French translation pairs.  \n",
    "这个项目的数据是成千上万句英语法语句子对的集合。\n",
    "\n",
    "[This question on Open Data Stack\n",
    "Exchange](http://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages)\n",
    "pointed me to the open translation site http://tatoeba.org/ which has\n",
    "downloads available at http://tatoeba.org/eng/downloads - and better\n",
    "yet, someone did the extra work of splitting language pairs into\n",
    "individual text files here: http://www.manythings.org/anki/\n",
    "\n",
    "The English to French pairs are too big to include in the repo, so\n",
    "download to ``data/eng-fra.txt`` before continuing. The file is a tab\n",
    "separated list of translation pairs:  \n",
    "句子对中间使用tab分割开两种语言。\n",
    "\n",
    "::\n",
    "\n",
    "    I am cold.    Je suis froid.\n",
    "\n",
    ".. Note::\n",
    "   Download the data from\n",
    "   [here](https://download.pytorch.org/tutorial/data.zip)\n",
    "   and extract it to the current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the character encoding used in the character-level RNN\n",
    "tutorials, we will be representing each word in a language as a one-hot\n",
    "vector, or giant vector of zeros except for a single one (at the index\n",
    "of the word). Compared to the dozens of characters that might exist in a\n",
    "language, there are many many more words, so the encoding vector is much\n",
    "larger. We will however cheat a bit and trim the data to only use a few\n",
    "thousand words per language.  \n",
    "类似于在字符级别的RNN指导教程中使用的字符编码， 我们将把一种语言中的每个单词表示成一个独热向量。\n",
    "对比于一种语言中有限的字符， 语言中的单词可谓是多得多了， 所以编码向量也就大了很多。 因此我们\n",
    "将偷个懒然后整理数据后只在每种语言中使用数千个单词。\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/word-encoding.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a unique index per word to use as the inputs and targets of\n",
    "the networks later. To keep track of all this we will use a helper class\n",
    "called ``Lang`` which has word → index (``word2index``) and index → word\n",
    "(``index2word``) dictionaries, as well as a count of each word\n",
    "``word2count`` to use to later replace rare words.  \n",
    "我们在输入和目标中需要对每个单词使用唯一索引。 为了记录所有的这些我们将使用一个辅助类``Lang``，\n",
    "拥有``单词到索引``和``索引到单词``的两个字典， 还有一个用数字统计每个单词出现的次数(``单词到数字``)。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are all in Unicode, to simplify we will turn Unicode\n",
    "characters to ASCII, make everything lowercase, and trim most\n",
    "punctuation.  \n",
    "这些文件使用的是 Unicode 编码， 为了简化，我们将把它转化成 ASCII 码，然后全部小写并整理大部分的标点。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split\n",
    "lines into pairs. The files are all English → Other Language, so if we\n",
    "want to translate from Other Language → English I added the ``reverse``\n",
    "flag to reverse the pairs.  \n",
    "为了读取数据文件我们将把文件且分成行，然后把行切分成对。文件是以 英语->其它语言 保存的，\n",
    "所以如果我们要从其它语言翻译成英语， 我们添加一个``reverse``标志来翻转语言对。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a *lot* of example sentences and we want to train\n",
    "something quickly, we'll trim the data set to only relatively short and\n",
    "simple sentences. Here the maximum length is 10 words (that includes\n",
    "ending punctuation) and we're filtering to sentences that translate to\n",
    "the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
    "earlier).  \n",
    "因为这里有太多的样本数据， 而我们想让训练更快， 我们将整理数据集成相对简短和简单的句子。\n",
    "这里最大长度是10个单词（包含结束符），然后我们预处理句子并转换成 “I am” 或 “He is” 等的形式。\n",
    "（提前替换省略符）。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:  \n",
    "所有数据准备的过程是：\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs  \n",
    "   读取文本文件切分成行，再切分成对\n",
    "-  Normalize text, filter by length and content  \n",
    "   标准化文本， 依据长度和内容预处理\n",
    "-  Make word lists from sentences in pairs  \n",
    "   从句子对中创建单词列表\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "Count of pairs:\n",
      "10853\n",
      "['vous n etes pas invite .', 'you aren t invited .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    print(\"Count of pairs:\")\n",
    "    print(len(pairs))\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.  \n",
    "一个循环神经网络（RNN），是一种工作在一个序列上的网络，并用它的输出作为下一步的输入。\n",
    "\n",
    "A [Sequence to Sequence network](http://arxiv.org/abs/1409.3215), or\n",
    "seq2seq network, or [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence.  \n",
    "一个 Sequence to Sequence network (序列到序列网络，编码解码网络），是一种包含两个\n",
    "循环神经网络（编码器和解码器）的神经网络模型。编码器读取一个序列作为输入，输出一个向量，\n",
    "解码器读取这个向量然后输出一个序列。\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/seq2seq.png)\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages.  \n",
    "与使用单个循环神经网络每步输入对应一个输出做序列预测不同，seq2seq模型令我们不用考虑序列长度和组织方式，这使得它十分符合用来处理语言翻译。\n",
    "\n",
    "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
    "black cat\". Most of the words in the input sentence have a direct\n",
    "translation in the output sentence, but are in slightly different\n",
    "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
    "construction there is also one more word in the input sentence. It would\n",
    "be difficult to produce a correct translation directly from the sequence\n",
    "of input words.  \n",
    "考虑这个句子 \"Je ne suis pas le chat noir\" → \"I am not the\n",
    "black cat\"。大部分的输入和输出单词都是直接对应的，但只有一些顺序不一致，\n",
    "比如  \"chat noir\" 和 \"black cat\"。这将使得从输入单词序列直接翻译出正确结果变得困难。\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the\n",
    "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
    "vector — a single point in some N dimensional space of sentences.  \n",
    "使用 seq2seq 模型编码器会创建一个向量， 在理想的情况下， 会编码输入句子的“含义”成一个向量，\n",
    "一个 N 维句子空间中的一个点。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.  \n",
    "seq2seq 网络的编码器是一个 RNN， 它针对输入句子的每个单词输出一些值。 对于输入的每个单词，\n",
    "编码器都输出一个向量和一个隐含状态， 然后在下个输入单词上使用隐含状态。\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/encoder-network.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and\n",
    "outputs a sequence of words to create the translation. \n",
    "解码器是另一个RNN，它把编码器的输出向量作为输入然后输出一个单词序列来作为翻译结果。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Decoder\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder.\n",
    "This last output is sometimes called the *context vector* as it encodes\n",
    "context from the entire sequence. This context vector is used as the\n",
    "initial hidden state of the decoder.  \n",
    "在这个最简单的seq2seq解码器上我们只维持编码器的输出。这个最后的输出常称之为*上下文向量*，\n",
    "因为它编码了整个序列文本。这个上下文向量被当成解码器的初始隐含状态来用。\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and\n",
    "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
    "token, and the first hidden state is the context vector (the encoder's\n",
    "last hidden state).  \n",
    "在每一步的解码过程中，都会给解码器一个输入令牌和一个隐含状态。初始输入令牌是起始符``<SOS>``,\n",
    "初始隐含状态是这个上下文向量。\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/decoder-network.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encourage you to train and observe the results of this model, but to\n",
    "save space we'll be going straight for the gold and introducing the\n",
    "Attention Mechanism.  \n",
    "我鼓励你训练并观测模型的输出， 但为了节约空间我们将直接介绍注意力机制。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder  注意力解码器\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder,\n",
    "that single vector carries the burden of encoding the entire sentence.  \n",
    "如果在编码器和解码器之间只有上下文向量传递信息， 则这个单独的上下文向量承载了编码所有输入序列信息的负担。\n",
    "\n",
    "Attention allows the decoder network to \"focus\" on a different part of\n",
    "the encoder's outputs for every step of the decoder's own outputs. First\n",
    "we calculate a set of *attention weights*. These will be multiplied by\n",
    "the encoder output vectors to create a weighted combination. The result\n",
    "(called ``attn_applied`` in the code) should contain information about\n",
    "that specific part of the input sequence, and thus help the decoder\n",
    "choose the right output words.  \n",
    "注意力机制允许解码器网络对于每一步解码器自己的输出“关注”编码器的输出的不同部分。  \n",
    "首先我们计算一个*注意力权重*集合。这些将会被编码器输出向量相乘然后产生一个组合权重。\n",
    "这个计算结果（代码中使用``attn_applied``表示）应该包含特定部分输入序列的信息，\n",
    "从而帮助解码器选择合适的输出单词。\n",
    "\n",
    "![](https://i.imgur.com/1152PYf.png)\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward\n",
    "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
    "Because there are sentences of all sizes in the training data, to\n",
    "actually create and train this layer we have to choose a maximum\n",
    "sentence length (input length, for encoder outputs) that it can apply\n",
    "to. Sentences of the maximum length will use all the attention weights,\n",
    "while shorter sentences will only use the first few.  \n",
    "计算注意力权重使用另一个前馈层``attn``，这个前馈层使用解码器的输入和隐含状态作为输入。\n",
    "因为在训练数据中包含有所有大小的句子，为了真正地创建并训练这个层我们必须选择一个\n",
    "能够在训练数据上使用的最大句子长度（编码器输入长度）。最长的句子使用所有的注意力权重，\n",
    "更短的句子只使用部分前面的权重。\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/attention-decoder-network.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
    "  limitation by using a relative position approach. Read about \"local\n",
    "  attention\" in [Effective Approaches to Attention-based Neural Machine\n",
    "  Translation](https://arxiv.org/abs/1508.04025)  \n",
    "    还有其它形式的注意力机制，相对使用长度限制，它使用相对位置的方法作为一种变通的方法。</p></div>\n",
    "\n",
    "Training\n",
    "========\n",
    "\n",
    "Preparing Training Data\n",
    "-----------------------\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the\n",
    "words in the input sentence) and target tensor (indexes of the words in\n",
    "the target sentence). While creating these vectors we will append the\n",
    "EOS token to both sequences.  \n",
    "为了进行训练，对于每对语言对我们需要一个输入张量（输入句子单词索引）和目标张量（目标句子单词索引）。\n",
    "当创建这些向量时我们将为两个句子都加上EOS令牌（结束令牌）。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "------------------\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track\n",
    "of every output and the latest hidden state. Then the decoder is given\n",
    "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
    "encoder as its first hidden state.  \n",
    "为了训练我们通过编码器运行输入句子，跟踪每个输出和最后的隐含状态。然后给解码器``<SOS>``\n",
    "令牌作为第一个输入，编码器的最后的隐含状态作为它的第一个隐含状态。\n",
    "\n",
    "\"Teacher forcing\" is the concept of using the real target outputs as\n",
    "each next input, instead of using the decoder's guess as the next input.\n",
    "Using teacher forcing causes it to converge faster but `when the trained\n",
    "network is exploited, it may exhibit\n",
    "instability <http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf>`__.  \n",
    "“导师驱动”是使用真实目标输出作为下一步输入，而不是使用解码器的预测值作为下一步的输入。\n",
    "使用导师驱动使其收敛更快但是`当这个训练好的网络拿来使用时`，它可能表现得不稳定。\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with\n",
    "coherent grammar but wander far from the correct translation -\n",
    "intuitively it has learned to represent the output grammar and can \"pick\n",
    "up\" the meaning once the teacher tells it the first few words, but it\n",
    "has not properly learned how to create the sentence from the translation\n",
    "in the first place.  \n",
    "你可以在语法一致的角度观察导师驱动网络的输出，但它却离正确的翻译差距太大，\n",
    "直观地来说，它学习到了输出语法的表示并能“提取”它的含义，一旦“导师”告诉它开头几个少量的单词，\n",
    "但是它不太可能学习到如何从最初的状的翻译中学习到如何产生句子。\n",
    "\n",
    "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
    "choose to use teacher forcing or not with a simple if statement. Turn\n",
    "``teacher_forcing_ratio`` up to use more of it.  \n",
    "由于 PyTorch 的自动梯度机制给我们的自由， 我们可以随机使用或不使用导师驱动机制，只要一个简单的if结构。\n",
    "提高``teacher_forcing_ratio（导师驱动率）``来更多使用导师驱动机制。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "   \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            print(\"decoder_output\")\n",
    "            print(decoder_output)\n",
    "            print(\"target_variable[di]\")\n",
    "            print(target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to print time elapsed and estimated time\n",
    "remaining given the current time and progress %.  \n",
    "辅助打印函数，打印一些运行状态信息。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:  \n",
    "整个训练过程看起来是这样的：\n",
    "\n",
    "-  Start a timer  \n",
    "   启动一个计时器\n",
    "-  Initialize optimizers and criterion  \n",
    "   初始化优化器和损失函数标准\n",
    "-  Create set of training pairs  \n",
    "   创建训练对集合\n",
    "-  Start empty losses array for plotting  \n",
    "   为后面画图启用空的误差数组\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (%\n",
    "of examples, time so far, estimated time) and average loss.  \n",
    "然后我们多次调用``train``并定时打印计算过程。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    " \n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting results  画结果图\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.  \n",
    "评价模型与训练类似，但是没有目标输出，所以我们每一步简单反馈解码器的预测输出到它本身。\n",
    "每一次它都预测一个单词然后我们将其添加到输出字符串。如果它预测输出 EOS 令牌，我们就在那里结束。\n",
    "我们也会存储解码器的注意力输出在后面显示。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "        \n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:  \n",
    "我们可以从训练集中随机选取句子来评价模型，然后打印出输入，目标输出，实际输出来做一些快速的主观判断。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Evaluating\n",
    "=======================\n",
    "\n",
    "With all these helper functions in place (it looks like extra work, but\n",
    "it's easier to run multiple experiments easier) we can actually\n",
    "initialize a network and start training.\n",
    "\n",
    "Remember that the input sentences were heavily filtered. For this small\n",
    "dataset we can use relatively small networks of 256 hidden nodes and a\n",
    "single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
    "reasonable results.\n",
    "\n",
    ".. Note:: \n",
    "   If you run this notebook you can train, interrupt the kernel,\n",
    "   evaluate, and continue training later. Comment out the lines where the\n",
    "   encoder and decoder are initialized and run ``trainIters`` again.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1219 -8.2469 -7.8807  ...  -7.9698 -8.1224 -7.9490\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0422 -8.0953 -7.9317  ...  -7.9482 -8.0557 -7.9297\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9737 -8.0353 -7.9056  ...  -7.9554 -7.9606 -7.9594\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 152\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9830 -8.0024 -7.9962  ...  -7.9226 -7.9733 -7.9432\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 356\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0184 -7.9858 -7.9853  ...  -7.9102 -7.9618 -7.9766\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0347 -7.9523 -7.9738  ...  -7.8850 -7.9483 -7.9278\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0383 -8.1307 -7.6689  ...  -7.9901 -8.0078 -7.9147\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9671 -7.8635 -7.7893  ...  -7.9405 -7.8974 -7.9442\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9221 -7.8441 -7.8100  ...  -7.9896 -7.8516 -7.8686\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 69\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9546 -7.7616 -7.8748  ...  -8.0114 -7.8705 -7.9045\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1413\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0119 -7.6713 -7.9207  ...  -7.9478 -7.8686 -7.8798\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9574 -7.6000 -7.9494  ...  -7.9392 -7.8107 -7.8971\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2306\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0251 -7.6294 -7.9818  ...  -8.0207 -7.8416 -7.8661\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9855 -7.6236 -7.9769  ...  -7.9757 -7.8744 -7.8692\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0165 -7.6063 -7.9552  ...  -7.8977 -7.9185 -7.8736\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0931 -8.0491 -7.3726  ...  -7.9784 -8.0896 -7.9833\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0156 -7.7844 -7.5535  ...  -7.9240 -8.0278 -7.9299\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9811 -7.6975 -7.6523  ...  -7.9330 -7.9834 -7.9530\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1297\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9678 -7.6911 -7.7105  ...  -7.9344 -7.9427 -7.8821\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0171 -7.5733 -7.7522  ...  -7.8615 -7.9513 -7.8936\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0542 -7.8472 -6.7085  ...  -7.9775 -7.9997 -7.9457\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9600 -7.5097 -7.0220  ...  -7.9377 -7.8761 -7.9467\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9083 -7.5299 -7.2505  ...  -7.9551 -7.8833 -7.8900\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1883\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9600 -7.4939 -7.2993  ...  -7.9628 -7.8874 -7.9118\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1471\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9834 -7.4948 -7.5101  ...  -7.8766 -7.9035 -7.9146\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9609 -7.3854 -7.5191  ...  -7.8951 -7.9064 -7.8744\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1596\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9529 -7.3484 -7.5743  ...  -7.8817 -7.9006 -7.9054\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0056 -7.2217 -7.5376  ...  -7.8367 -7.8733 -7.9407\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0586 -7.7599 -6.3235  ...  -7.9811 -7.9646 -8.0045\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9373 -7.4309 -6.7405  ...  -7.9561 -7.8673 -8.0245\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9287 -7.4750 -7.0553  ...  -7.9978 -7.8501 -7.9374\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 200\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9965 -7.5350 -7.3236  ...  -7.9891 -7.8723 -7.8982\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0291 -7.2468 -7.3625  ...  -7.9239 -7.9058 -7.8811\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0789 -7.6039 -5.9437  ...  -7.9561 -7.9148 -7.9883\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 222\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0086 -7.5016 -6.6230  ...  -7.9352 -7.9442 -7.9601\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9625 -7.0972 -6.6103  ...  -7.9289 -7.8557 -8.0352\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 61\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9276 -7.1874 -7.0409  ...  -7.9094 -7.8639 -7.9918\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 539\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9077 -7.0599 -7.1032  ...  -7.8912 -7.8394 -7.9138\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1133\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9179 -7.0965 -7.0759  ...  -7.8803 -7.7762 -7.9778\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9836 -6.8079 -7.1224  ...  -7.8337 -7.8043 -7.9162\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0466 -7.4355 -5.9108  ...  -7.9934 -7.9065 -7.9883\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9181 -6.9551 -6.3944  ...  -7.9257 -7.8050 -8.0194\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9124 -6.9714 -6.7648  ...  -7.9457 -7.7815 -7.9356\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 629\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9012 -6.9256 -7.0582  ...  -7.9697 -7.8015 -7.9181\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1390\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9864 -7.0487 -7.2335  ...  -7.9449 -7.8084 -7.9304\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0091 -6.6300 -7.1844  ...  -7.8672 -7.8209 -7.9033\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0104 -7.0817 -5.2065  ...  -7.9985 -7.9226 -8.0570\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.8961 -6.4104 -5.6488  ...  -7.9481 -7.7840 -7.9991\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 16\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9587 -6.5326 -6.1894  ...  -7.8789 -7.7695 -7.8819\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 88\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9070 -6.5731 -6.4481  ...  -7.9051 -7.7930 -7.8911\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 904\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9108 -6.4520 -6.6032  ...  -7.9056 -7.7323 -7.8749\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9686 -6.0246 -6.6753  ...  -7.8521 -7.7746 -7.8939\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0425 -6.7672 -4.5452  ...  -7.9629 -7.8196 -7.9614\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 77\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9122 -6.5859 -5.6155  ...  -7.9310 -7.7440 -7.9614\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9042 -6.1045 -5.6874  ...  -7.9367 -7.7063 -8.0160\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 262\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9288 -6.3543 -6.3187  ...  -7.8971 -7.7220 -7.9367\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0180 -5.6881 -6.2743  ...  -7.8353 -7.7503 -7.9210\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0265 -5.9628 -4.3382  ...  -8.0446 -7.8146 -7.9070\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9131 -5.0237 -4.8573  ...  -7.9331 -7.6741 -7.9296\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 16\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9518 -5.1040 -5.4318  ...  -7.8471 -7.6653 -7.8724\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 238\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9564 -5.2921 -5.8291  ...  -7.8878 -7.6143 -7.8399\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 525\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9993 -5.4444 -6.2509  ...  -7.8896 -7.6493 -7.9037\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 619\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9474 -5.5718 -6.5969  ...  -7.9055 -7.7099 -7.9118\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0659 -4.4101 -6.2293  ...  -7.7741 -7.6874 -7.8619\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1067 -5.7358 -3.8830  ...  -7.9258 -7.8367 -7.9256\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9614 -4.6457 -4.4421  ...  -7.8610 -7.7103 -7.9343\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9253 -4.4328 -5.1098  ...  -7.8567 -7.6534 -7.8784\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9127 -4.9849 -5.9020  ...  -7.9029 -7.7090 -7.8319\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 357\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9580 -5.1259 -6.0034  ...  -7.8749 -7.6890 -7.9001\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 365\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9691 -5.1590 -6.2219  ...  -7.8684 -7.6758 -7.9195\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0937 -3.7794 -5.8004  ...  -7.7712 -7.6825 -7.8757\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1800 -5.4121 -2.4671  ...  -8.0418 -7.9404 -8.0167\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 77\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9397 -5.1446 -3.8646  ...  -7.8845 -7.7529 -8.0245\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9392 -4.4087 -3.9933  ...  -7.8916 -7.7297 -8.1011\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9384 -4.6533 -4.9587  ...  -7.8771 -7.7344 -7.9354\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 707\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9147 -4.8795 -5.4099  ...  -7.8651 -7.7263 -8.0020\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1158 -3.4957 -4.9386  ...  -7.7552 -7.7412 -7.9565\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1513 -4.8800 -2.3638  ...  -8.1179 -7.9469 -8.0360\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9832 -4.4653 -3.7795  ...  -7.8762 -7.7947 -7.9333\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0210 -3.7016 -3.9484  ...  -7.8911 -7.8136 -8.0712\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0035 -3.9826 -4.8224  ...  -7.8603 -7.7703 -7.9269\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2005\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9636 -4.3367 -5.4259  ...  -7.7690 -7.7516 -7.9998\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 539\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9590 -4.2170 -5.4732  ...  -7.7917 -7.7345 -7.9123\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1226\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0283 -4.1510 -5.3844  ...  -7.8222 -7.6861 -7.9539\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 102\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0346 -4.3189 -5.6779  ...  -7.8206 -7.7262 -7.9005\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 46\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0769 -4.1900 -5.5691  ...  -7.7929 -7.6755 -7.8493\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2840 -2.6717 -5.0286  ...  -7.8418 -7.8169 -7.9597\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1504 -4.8784 -2.7399  ...  -8.1501 -7.9574 -8.0254\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 75\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9909 -4.4142 -3.9148  ...  -7.9629 -7.7438 -8.0225\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9295 -4.0993 -4.5336  ...  -7.9497 -7.6656 -7.9178\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9424 -4.1815 -5.0940  ...  -7.9588 -7.6480 -7.8619\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 304\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9668 -4.3173 -5.5850  ...  -7.8363 -7.7311 -7.8857\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 124\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9839 -4.4900 -5.8404  ...  -7.8116 -7.7041 -7.8503\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 909\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0016 -4.5675 -5.9989  ...  -7.7884 -7.6734 -7.9054\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2057 -2.6982 -5.4205  ...  -7.7884 -7.7858 -7.9670\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1813 -4.2525 -2.9985  ...  -8.2897 -8.0011 -8.1092\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0273 -4.0138 -4.4046  ...  -8.0022 -7.7923 -7.9698\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0058 -3.4390 -4.8550  ...  -7.9623 -7.7355 -7.9583\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 532\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9560 -3.5406 -5.3442  ...  -7.9467 -7.7207 -7.9559\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 32\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9863 -3.6522 -5.5709  ...  -7.9398 -7.7393 -7.9383\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 102\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0451 -3.3834 -5.7082  ...  -7.9216 -7.7525 -7.9088\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 103\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-7.9538 -3.8972 -6.0019  ...  -7.9147 -7.7176 -7.9299\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3191 -1.8069 -5.6628  ...  -8.0435 -7.9842 -8.1219\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1345 -3.9032 -3.0867  ...  -8.2319 -8.0055 -8.1289\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3729 -2.4140 -3.8622  ...  -8.4672 -8.2106 -8.4595\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 16\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3479 -2.1872 -4.3796  ...  -8.2801 -8.0413 -8.2883\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 32\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1863 -2.3368 -4.8961  ...  -8.1624 -7.8771 -8.1827\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9900  -0.9187  -5.4870  ...   -8.7214  -8.6047  -8.7784\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3088 -4.4544 -2.1716  ...  -8.5548 -8.1340 -8.3376\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3712 -3.1761 -3.1056  ...  -8.6449 -8.2232 -8.5868\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2492 -2.4847 -3.9130  ...  -8.3340 -7.9863 -8.3336\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0930 -2.6750 -4.7320  ...  -8.1313 -7.8194 -8.0197\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 520\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0753 -2.6213 -5.2201  ...  -8.0725 -7.7820 -8.0483\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6172 -1.2198 -5.2343  ...  -8.4092 -8.2380 -8.4456\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6512 -5.3150 -1.0626  ...  -8.8253 -8.4530 -8.6248\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4598 -3.7980 -1.7899  ...  -8.6629 -8.2901 -8.6177\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3053 -2.7562 -2.7024  ...  -8.3660 -8.0575 -8.3931\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1417\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2261 -2.4789 -3.4012  ...  -8.2624 -8.0035 -8.2771\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 159\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0919 -3.0326 -4.1716  ...  -8.0771 -7.7911 -8.0844\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1212\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0571 -3.3397 -4.8949  ...  -7.9186 -7.7591 -7.9629\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4528 -1.5461 -4.4088  ...  -8.1848 -8.0636 -8.2699\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8674  -5.2178  -0.7817  ...   -9.0836  -8.7738  -8.8870\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1385 -3.9986 -2.4944  ...  -8.1850 -7.9375 -8.1700\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1497 -2.9456 -3.0454  ...  -8.1635 -7.8705 -8.1328\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 56\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0281 -3.1767 -4.0504  ...  -7.9706 -7.7478 -8.0593\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6095 -1.2385 -3.8903  ...  -8.3781 -8.2249 -8.4842\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5973 -4.5266 -1.1478  ...  -8.8595 -8.5204 -8.6507\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1155 -3.5439 -2.8421  ...  -8.2113 -7.9356 -8.1558\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 40\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0621 -3.3033 -3.8780  ...  -8.0729 -7.8117 -8.0677\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 39\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0860 -3.1499 -4.5880  ...  -7.9953 -7.7982 -7.9466\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 279\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.0310 -3.3038 -5.0959  ...  -8.0051 -7.8010 -8.0363\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7017 -1.0509 -4.8589  ...  -8.4575 -8.3497 -8.5265\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4641 -4.0015 -1.5349  ...  -8.5782 -8.2302 -8.4937\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5656 -2.3626 -2.5905  ...  -8.7033 -8.3392 -8.7352\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.6965  -1.5840  -3.7453  ...   -8.7076  -8.4284  -8.8111\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1083\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3835 -1.9782 -4.6307  ...  -8.3110 -8.0367 -8.3577\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 84\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3282 -2.0534 -4.9461  ...  -8.2614 -7.9526 -8.3283\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4333  -0.5527  -5.4908  ...   -9.2345  -9.0221  -9.3093\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8267  -4.5041  -0.9895  ...   -8.9946  -8.6405  -8.7864\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8105  -2.8851  -2.1011  ...   -8.9567  -8.6189  -8.9542\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.6817  -1.8901  -3.2385  ...   -8.6586  -8.4034  -8.7821\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 69\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4783 -1.8780 -4.0178  ...  -8.3848 -8.0767 -8.4729\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8466  -1.6272  -4.0013  ...   -8.8637  -8.5413  -8.9532\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 277\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5247 -1.9330 -4.4065  ...  -8.5032 -8.1843 -8.4993\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5003 -1.7133 -4.7888  ...  -8.4003 -8.1712 -8.4660\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6299  -0.4965  -5.3584  ...   -9.3563  -9.1928  -9.4574\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.5350  -5.6368  -0.4240  ...   -9.6678  -9.3238  -9.5607\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5313 -3.4008 -1.4470  ...  -8.5410 -8.3526 -8.6256\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6441 -2.2136 -1.8883  ...  -8.6643 -8.4171 -8.8081\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 116\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5304 -1.9616 -2.8831  ...  -8.3751 -8.1938 -8.5792\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4270  -0.6371  -3.4095  ...   -9.1782  -9.0307  -9.2895\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      " -9.0184  -5.4314  -1.5188  ...   -9.1755  -8.8085  -8.9938\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.0565  -4.2198  -2.5156  ...   -9.2351  -8.8396  -9.1833\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.7742  -3.1062  -3.4210  ...   -8.7839  -8.4688  -8.8107\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5572 -2.9007 -4.1756  ...  -8.4752 -8.2079 -8.4291\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 33\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5211 -2.9245 -4.6040  ...  -8.3240 -8.1503 -8.4508\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8826  -2.8055  -4.4081  ...   -8.8326  -8.5731  -8.9332\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2107\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6194 -2.8742 -4.7811  ...  -8.5987 -8.2932 -8.6991\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7049 -2.4945 -5.1040  ...  -8.5341 -8.3666 -8.6886\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6073  -1.1173  -5.4383  ...   -9.2713  -9.1379  -9.4115\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8813  -4.5693  -1.3364  ...   -9.0652  -8.6733  -8.8791\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8354  -3.2020  -2.3233  ...   -9.0740  -8.6889  -9.0457\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.7029  -1.8246  -3.1312  ...   -8.7409  -8.4122  -8.7709\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 79\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4498 -1.8597 -3.9613  ...  -8.4320 -8.0961 -8.5144\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 525\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6023 -1.7205 -4.1620  ...  -8.4766 -8.1750 -8.5893\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5666 -1.6731 -4.2861  ...  -8.4444 -8.1075 -8.4181\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1235\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4229 -1.9151 -4.5176  ...  -8.2531 -7.9881 -8.3000\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7884  -0.3889  -5.3017  ...   -9.5322  -9.3341  -9.5372\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1285  -5.2875  -0.8430  ...   -9.2925  -8.9309  -9.1139\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9622  -3.8975  -1.8021  ...   -9.2308  -8.8365  -9.1590\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 16\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.7540  -2.7104  -2.2515  ...   -8.7559  -8.4114  -8.7706\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 295\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5864 -2.4174 -2.8606  ...  -8.5342 -8.1512 -8.4752\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1002\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3723 -2.3989 -3.7583  ...  -8.2802 -8.0159 -8.3603\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 525\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4607 -2.2049 -3.8716  ...  -8.3303 -8.0373 -8.4244\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 811\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4090 -2.0519 -4.1620  ...  -8.2814 -8.0186 -8.2861\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 319\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2323 -2.4313 -4.4396  ...  -8.0861 -7.9045 -8.1513\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.3307  -0.5904  -4.7621  ...   -9.0990  -8.9341  -9.1297\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8200  -5.9358  -0.8733  ...   -9.1126  -8.7237  -8.8134\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2950 -3.8248 -2.1699  ...  -8.3398 -8.1510 -8.3126\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4371 -2.5827 -2.5759  ...  -8.4669 -8.2454 -8.5426\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 304\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3218 -2.6459 -3.5260  ...  -8.1524 -8.0066 -8.2485\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1173\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1197 -3.1571 -4.3227  ...  -7.9956 -7.8363 -8.0557\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 574\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1447 -3.0739 -4.3004  ...  -7.9725 -7.8087 -8.0369\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 545\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1847 -2.9420 -4.7061  ...  -7.9755 -7.7657 -7.9465\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2302 -2.4610 -4.5709  ...  -8.0623 -7.9215 -8.1168\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1078\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2213 -2.7395 -4.8753  ...  -7.9102 -7.8773 -8.0875\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.0675  -5.8432  -1.1016  ...   -9.2003  -8.8250  -9.0684\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4392 -3.6001 -2.3972  ...  -8.3996 -8.1973 -8.4873\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4834 -2.3230 -3.0386  ...  -8.4898 -8.2505 -8.6343\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 102\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4680 -2.0198 -3.7357  ...  -8.3268 -8.0962 -8.4030\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 178\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2333 -2.5594 -4.3627  ...  -8.0924 -7.8256 -8.1651\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.0197  -0.7208  -4.7004  ...   -8.8132  -8.6100  -8.8825\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.2003  -5.8830  -1.5898  ...   -9.3747  -8.9262  -9.2033\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3454 -4.1485 -3.0168  ...  -8.3780 -8.0196 -8.4026\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 40\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2091 -3.4751 -3.8498  ...  -8.1959 -7.8626 -8.2457\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 159\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1779 -3.3022 -4.4935  ...  -8.0700 -7.7606 -8.1260\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 27\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1751 -3.1691 -5.1067  ...  -7.9658 -7.7942 -8.0264\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 484\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2071 -2.8324 -5.1336  ...  -8.0097 -7.8045 -8.1126\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1842  -0.6304  -5.3575  ...   -8.9175  -8.7107  -8.9951\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9619  -5.3987  -1.6336  ...   -9.1835  -8.7175  -9.0075\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.7737  -4.0964  -2.9202  ...   -9.0451  -8.6081  -9.0477\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3930 -2.6868 -3.7506  ...  -8.4834 -8.1255 -8.5286\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 798\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2825 -2.4761 -4.6011  ...  -8.2701 -7.9630 -8.2989\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1320\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1446 -2.7337 -5.3227  ...  -8.0796 -7.7957 -8.1335\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 539\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2510 -2.3824 -5.3444  ...  -8.1279 -7.8814 -8.1496\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 709\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1467 -2.8798 -5.4916  ...  -8.0555 -7.7997 -8.0546\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.3168  -0.5358  -5.8264  ...   -9.0830  -8.8832  -9.1224\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1597  -6.1394  -1.5224  ...   -9.3321  -8.8727  -9.1653\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8753  -4.9256  -2.8195  ...   -9.0974  -8.6595  -9.1472\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5316 -3.3687 -3.8318  ...  -8.5673 -8.2326 -8.7200\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 383\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3610 -3.3110 -4.5719  ...  -8.3131 -8.0128 -8.4576\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.3419  -1.1794  -5.2371  ...   -9.1305  -8.9337  -9.2499\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1859  -6.1636  -1.2097  ...   -9.3507  -8.9007  -9.1907\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.0745  -4.9439  -2.8640  ...   -9.3024  -8.9044  -9.3635\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6684 -3.5227 -3.8700  ...  -8.7209 -8.3673 -8.8339\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1865\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.0006  -2.9172  -4.2393  ...   -8.8407  -8.5349  -9.0003\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 539\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9635  -2.8885  -4.9368  ...   -8.7468  -8.5077  -8.8789\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1393\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.8090 -2.8494 -5.0866  ...  -8.7173 -8.2390 -8.7647\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1604  -2.5065  -5.6641  ...   -8.9765  -8.6684  -9.1098\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.2318  -1.1330  -6.3440  ...   -9.9166  -9.7105 -10.0780\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8915  -7.9587  -0.4545  ...  -10.0374  -9.6412  -9.9467\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4256  -6.7744  -2.0843  ...   -9.7049  -9.3225  -9.8020\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4986 -4.9875 -2.9805  ...  -8.5733 -8.3052 -8.7456\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 26\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3397 -4.3296 -3.6523  ...  -8.2359 -8.0556 -8.4190\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.7592  -4.6986  -3.8620  ...   -8.9178  -8.6426  -9.0861\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 927\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5143 -4.1921 -3.7746  ...  -8.4762 -8.1716 -8.5845\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 490\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3378 -4.1028 -4.2325  ...  -8.3044 -7.9802 -8.3706\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1430  -2.1432  -4.5004  ...   -8.8979  -8.7167  -9.0551\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.3706  -7.9498  -0.2094  ...  -10.5116 -10.1371 -10.4096\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5090 -5.1387 -1.4952  ...  -8.4805 -8.2148 -8.5441\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 40\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2333 -4.3363 -2.7133  ...  -8.1699 -7.9087 -8.2644\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 613\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1878 -3.7412 -3.3364  ...  -8.0786 -7.8824 -8.3447\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 539\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2069 -3.3967 -3.8269  ...  -8.0522 -7.9006 -8.2140\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1269\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3602 -2.9131 -3.7508  ...  -8.0786 -7.9789 -8.3470\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1332\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3114 -3.0210 -4.1022  ...  -8.0795 -7.9540 -8.2915\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1910\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3003 -3.1547 -4.1289  ...  -8.0446 -7.8617 -8.2113\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.2934  -0.9950  -4.2469  ...   -8.9114  -8.8060  -9.1066\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6464  -6.9214  -0.5268  ...   -9.7914  -9.4228  -9.6564\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 75\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5773 -4.6444 -1.7166  ...  -8.5876 -8.2318 -8.7138\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4785 -3.1077 -2.6260  ...  -8.4217 -8.0639 -8.5143\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4388 -2.8142 -3.2407  ...  -8.4075 -8.0060 -8.4013\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 304\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4272 -2.5901 -4.1734  ...  -8.2045 -7.9685 -8.3019\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2159\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4087 -2.7336 -4.5752  ...  -8.1951 -7.9451 -8.2637\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 902\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4902 -2.2731 -4.6981  ...  -8.2517 -8.0461 -8.3244\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7282  -0.5814  -5.3208  ...   -9.3768  -9.2616  -9.5344\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1018  -6.2314  -0.9755  ...   -9.3099  -8.8869  -9.1128\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 75\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3441 -4.4373 -2.5190  ...  -8.4242 -8.0477 -8.5001\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 544\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2715 -3.4640 -3.6913  ...  -8.2518 -7.9076 -8.2619\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 545\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3855 -2.6231 -4.5294  ...  -8.2314 -7.8801 -8.2136\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 183\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3270 -2.7915 -5.1375  ...  -8.1097 -7.8376 -8.2157\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.5309  -0.5866  -5.8065  ...   -9.2103  -9.0438  -9.3438\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7497  -8.4306  -0.6412  ...   -9.8564  -9.4576  -9.7973\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4396  -7.5385  -2.5544  ...   -9.7174  -9.3175  -9.8275\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4674 -5.6056 -3.1281  ...  -8.5822 -8.2224 -8.6890\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 793\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3129 -4.8019 -3.5895  ...  -8.2307 -7.9437 -8.3590\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7556 -2.4632 -3.7304  ...  -8.5335 -8.2771 -8.6272\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7975  -7.7351  -0.4861  ...   -9.9094  -9.5494  -9.8593\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4171  -6.5882  -2.4000  ...   -9.7249  -9.3403  -9.8196\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3697 -4.4692 -3.2218  ...  -8.4869 -8.1629 -8.6047\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2958 -3.6013 -3.9990  ...  -8.3040 -7.9850 -8.2904\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 580\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.1989 -3.7080 -4.3765  ...  -8.1916 -7.9023 -8.2407\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 539\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2962 -3.4337 -4.6246  ...  -8.1979 -7.9235 -8.2268\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2106\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2649 -3.4384 -4.9632  ...  -8.1447 -7.9331 -8.1909\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.0442  -1.1819  -4.8061  ...   -8.7849  -8.5784  -8.8426\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.0414  -7.6143  -0.3846  ...  -10.2219  -9.8018 -10.1055\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.5998  -6.3478  -2.3758  ...   -9.9527  -9.5420 -10.0148\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5824 -4.0266 -3.0926  ...  -8.7114 -8.3728 -8.8344\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 195\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4792 -3.6953 -3.2812  ...  -8.4559 -8.1326 -8.5423\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.2073  -1.1605  -3.8290  ...   -9.0755  -8.7835  -9.1254\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.9268  -6.9094  -0.3833  ...  -10.0847  -9.7147 -10.0160\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6437 -3.6590 -2.0397  ...  -8.5245 -8.3943 -8.7668\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 125\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4257 -3.2021 -3.3695  ...  -8.2629 -8.0691 -8.4910\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 295\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4555 -2.8247 -4.1426  ...  -8.2905 -8.0525 -8.4343\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1214\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4247 -2.5273 -4.9442  ...  -8.2351 -8.0471 -8.4039\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 524\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4110 -2.5450 -5.1617  ...  -8.1241 -7.9340 -8.2815\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8333  -0.4583  -5.7328  ...   -9.4900  -9.3324  -9.6479\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.5931  -6.3664  -0.8063  ...   -9.7127  -9.3686  -9.6637\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4151 -4.2299 -2.7702  ...  -8.3124 -8.0943 -8.5011\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 40\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3081 -3.3648 -4.0992  ...  -8.1955 -7.9357 -8.3891\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1105\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2412 -2.9078 -5.1309  ...  -8.1470 -7.8965 -8.3330\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3374 -2.6160 -5.1126  ...  -8.2849 -7.9148 -8.2988\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1268\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3463 -2.6629 -5.4501  ...  -8.2314 -7.9060 -8.2516\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8085  -0.4079  -6.3003  ...   -9.6135  -9.3530  -9.6872\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4051  -6.1593  -1.0364  ...   -9.4924  -9.1048  -9.4343\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4132 -4.0771 -3.0567  ...  -8.3781 -8.0191 -8.4690\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 40\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3963 -3.1658 -4.2440  ...  -8.2886 -7.9274 -8.4009\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 102\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6608 -2.1095 -5.1772  ...  -8.4530 -8.1581 -8.5649\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 295\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6986 -2.1699 -5.3256  ...  -8.5014 -8.1106 -8.5231\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1500\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5882 -2.2316 -5.9465  ...  -8.3880 -8.0408 -8.5270\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.2413  -0.3203  -6.9896  ...   -9.9701  -9.7091 -10.0573\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1378  -5.8934  -1.4441  ...   -9.2789  -8.8453  -9.1895\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1615  -4.8817  -3.8105  ...   -9.4743  -9.0422  -9.5628\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 16\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.7739  -2.9521  -4.1074  ...   -8.7495  -8.3972  -8.8167\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 20\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7185 -2.4845 -4.9656  ...  -8.5654 -8.2378 -8.6655\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.0683  -0.4334  -6.3559  ...   -9.8556  -9.5998  -9.9670\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4930  -6.0766  -0.7247  ...   -9.5727  -9.1488  -9.5081\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8603  -4.3290  -2.7483  ...   -9.0969  -8.6936  -9.2252\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6064 -2.6547 -4.2129  ...  -8.6611 -8.2711 -8.7749\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8718  -2.1072  -5.0996  ...   -8.7670  -8.4007  -8.7454\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 217\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9042  -2.0378  -5.7068  ...   -8.7933  -8.4302  -8.7721\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 616\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.9164 -2.2191 -5.9430  ...  -8.6752 -8.3763 -8.6942\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1139\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.8433 -1.8193 -5.9913  ...  -8.5994 -8.3173 -8.7646\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.7279  -0.2265  -7.3150  ...  -10.4319 -10.1508 -10.5368\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8877  -6.8481  -0.4564  ...   -9.9564  -9.5100  -9.8705\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.2591  -5.3238  -2.5653  ...   -9.5182  -9.0731  -9.5997\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4339 -3.3850 -3.7020  ...  -8.5228 -8.1570 -8.6365\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4034 -2.5828 -4.4092  ...  -8.3939 -8.0004 -8.3505\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2770\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3727 -2.6324 -4.8204  ...  -8.3250 -7.9227 -8.2454\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 709\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3965 -2.6579 -5.2550  ...  -8.3231 -7.9485 -8.2817\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2283\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4053 -2.4967 -5.4070  ...  -8.2711 -7.9884 -8.3177\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.1325  -0.2695  -6.3517  ...   -9.9143  -9.6431  -9.9435\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.0954  -7.2300  -0.3845  ...  -10.1665  -9.7680 -10.0767\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7151 -3.7823 -2.0602  ...  -8.6456 -8.3933 -8.8334\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8231  -2.3700  -3.1510  ...   -8.7677  -8.4799  -9.0230\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 60\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6054 -2.4776 -4.1216  ...  -8.5166 -8.2671 -8.7585\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.1811  -0.3112  -5.4991  ...   -9.9687  -9.7719 -10.1464\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6390  -6.5153  -0.9159  ...   -9.6750  -9.2624  -9.6190\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6997 -3.5737 -2.9616  ...  -8.5376 -8.3201 -8.7618\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9556  -2.2919  -4.1257  ...   -8.8609  -8.5703  -9.1156\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9038  -2.2989  -4.7162  ...   -8.7817  -8.4564  -8.8895\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 865\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7612 -2.3589 -5.2668  ...  -8.6358 -8.2927 -8.7443\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 477\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7972 -2.1560 -5.1707  ...  -8.5716 -8.2139 -8.6951\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.6834  -0.2079  -6.9707  ...  -10.4348 -10.1715 -10.5345\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7209  -6.7672  -1.4930  ...   -9.7999  -9.3751  -9.7455\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4000  -5.6810  -4.0115  ...   -9.6800  -9.2868  -9.8189\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5401 -3.6642 -4.6329  ...  -8.6639 -8.3010 -8.8062\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4115 -2.9517 -5.2434  ...  -8.3797 -8.0229 -8.4059\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 651\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4844 -2.7973 -5.3334  ...  -8.3802 -8.0115 -8.4652\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.1625  -0.3038  -6.8355  ...   -9.9284  -9.6670 -10.0112\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6089  -6.7370  -0.8763  ...   -9.7242  -9.3208  -9.6300\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6539  -5.9077  -3.6992  ...   -9.9760  -9.5871 -10.0946\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.7235  -3.6385  -4.4474  ...   -8.8149  -8.5275  -9.0025\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 72\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6986 -2.8191 -4.6573  ...  -8.6767 -8.3247 -8.8691\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 525\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9472  -2.6059  -5.2635  ...   -8.7927  -8.4742  -9.0342\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1105\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9081  -2.3170  -6.0573  ...   -8.7177  -8.4897  -9.0306\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.6658  -0.2432  -7.2048  ...  -10.4510 -10.2260 -10.6024\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6787  -7.9488  -1.2293  ...   -9.7676  -9.3424  -9.6658\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.1314  -6.9790  -3.6017  ...   -9.4218  -9.0363  -9.5612\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3913 -5.3509 -4.5650  ...  -8.5231 -8.1698 -8.6790\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3062 -4.6833 -5.3424  ...  -8.3461 -7.9744 -8.3444\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 37\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4415 -4.2377 -5.7476  ...  -8.2422 -8.0253 -8.3607\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4485  -1.5108  -6.2577  ...   -9.1552  -8.9403  -9.2340\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8188  -7.7287  -0.7339  ...   -9.9120  -9.5209  -9.7802\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 75\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6160 -5.3293 -2.4247  ...  -8.6017 -8.2443 -8.7730\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5765 -4.0648 -3.6644  ...  -8.5171 -8.1059 -8.6265\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5386 -3.7150 -4.4274  ...  -8.5277 -8.0894 -8.5634\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 487\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6029 -3.4986 -5.0389  ...  -8.5160 -8.1080 -8.5825\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1283\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7099 -3.3469 -5.4100  ...  -8.5670 -8.2537 -8.7075\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.9834  -0.7074  -6.4226  ...   -9.7165  -9.4881  -9.8508\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7092  -7.6914  -1.6295  ...   -9.8507  -9.3845  -9.7511\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.3964  -6.8504  -4.3588  ...   -9.7240  -9.3177  -9.8464\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5637 -5.0502 -5.1191  ...  -8.6924 -8.3553 -8.8389\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 304\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3529 -3.8782 -5.6071  ...  -8.2617 -7.9691 -8.3935\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 26\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4443 -3.3379 -5.6938  ...  -8.2133 -7.9928 -8.3339\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 539\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5365 -3.0270 -6.1018  ...  -8.3037 -8.0843 -8.4458\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1227\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5606 -3.0328 -6.1654  ...  -8.3637 -8.1130 -8.4667\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7123 -2.6824 -6.5984  ...  -8.4964 -8.2942 -8.6502\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 993\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6392 -2.6402 -6.7107  ...  -8.4258 -8.1554 -8.4611\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.9143  -0.4523  -7.3070  ...   -9.6346  -9.3812  -9.6717\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7470  -7.9623  -1.1872  ...   -9.9033  -9.4173  -9.7492\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6610  -7.5468  -4.1803  ...  -10.0118  -9.5922 -10.1379\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6513 -5.4174 -4.8267  ...  -8.7769 -8.4118 -8.9074\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 148\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3279 -4.5357 -5.4858  ...  -8.3250 -7.9655 -8.3115\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 202\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5546 -3.9720 -5.4270  ...  -8.5078 -8.0636 -8.4930\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 33\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6107 -3.9502 -5.4505  ...  -8.4671 -8.1393 -8.5404\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1404\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7364 -3.6630 -5.6417  ...  -8.5902 -8.2056 -8.6435\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7073  -0.9101  -6.3818  ...   -9.4840  -9.1865  -9.5291\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.9394  -7.9867  -0.6471  ...  -10.1641  -9.6616  -9.9685\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8546  -7.4148  -3.7464  ...  -10.2357  -9.8066 -10.3111\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8383  -5.1197  -4.5687  ...   -9.0328  -8.6791  -9.1289\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 26\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5263 -3.6789 -4.6638  ...  -8.5077 -8.2032 -8.5816\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6721 -2.9961 -5.4991  ...  -8.5000 -8.2605 -8.6578\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1227\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7576 -2.8589 -5.2114  ...  -8.6380 -8.2936 -8.6576\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 490\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6681 -2.9292 -5.5893  ...  -8.5227 -8.1867 -8.5297\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 709\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5762 -3.1688 -5.8562  ...  -8.4773 -8.1282 -8.4996\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 404\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6454 -2.6578 -6.1886  ...  -8.5092 -8.2452 -8.5943\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.1516  -0.3937  -6.9367  ...   -9.9280  -9.6700  -9.9810\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8012  -8.1849  -0.7553  ...   -9.9159  -9.4384  -9.8318\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5313 -5.5433 -2.7827  ...  -8.4904 -8.1893 -8.6395\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5304 -3.9688 -3.7166  ...  -8.5258 -8.1682 -8.7190\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 152\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4354 -3.6567 -4.6943  ...  -8.3583 -8.0334 -8.4991\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 356\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4368 -3.2822 -5.3508  ...  -8.2264 -7.9477 -8.3899\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.5157  -0.5783  -6.0968  ...   -9.2730  -9.0049  -9.3523\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      "-10.2079  -8.4810  -0.5949  ...  -10.3650  -9.9121 -10.2111\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7681  -7.6726  -3.3417  ...  -10.0872  -9.6740 -10.2034\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4442 -5.2064 -3.7807  ...  -8.5622 -8.1983 -8.6716\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 367\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3148 -4.2739 -4.5177  ...  -8.3168 -7.8990 -8.3013\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.6931  -4.8498  -4.8836  ...   -8.9376  -8.5122  -8.9818\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1308\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5560 -3.3448 -4.3135  ...  -8.6978 -8.1907 -8.6089\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 280\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5901 -3.0296 -4.7321  ...  -8.5305 -8.1079 -8.5621\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6942 -2.7964 -5.3020  ...  -8.5063 -8.2051 -8.6463\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8403  -0.5172  -5.6648  ...   -9.5940  -9.3166  -9.6237\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.1723  -8.0184  -0.4267  ...  -10.2157  -9.8466 -10.0327\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6695 -5.0011 -1.8344  ...  -8.5827 -8.3508 -8.6628\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6163 -3.5618 -2.4564  ...  -8.5745 -8.2239 -8.7429\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 663\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3504 -3.4300 -3.7254  ...  -8.2999 -7.9653 -8.3372\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3811 -3.4285 -3.7717  ...  -8.3499 -7.9133 -8.2643\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 240\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4496 -3.3704 -4.0162  ...  -8.2785 -7.9108 -8.2369\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 480\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6590 -2.6817 -3.7315  ...  -8.3922 -7.9715 -8.3763\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.2036  -0.2900  -4.7345  ...   -9.9653  -9.6259  -9.9267\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.5475  -8.5217  -0.8239  ...  -10.6125 -10.1400 -10.4776\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.9469  -5.3662  -2.2980  ...   -8.8351  -8.6209  -9.0371\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7824 -3.4909 -3.0591  ...  -8.6863 -8.4105 -8.9249\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1478\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4555 -3.6204 -4.0903  ...  -8.3485 -8.0426 -8.5025\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8291  -0.4701  -4.7175  ...   -9.6525  -9.3540  -9.6579\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.1064  -8.8523  -0.9211  ...  -10.2848  -9.8302 -10.1409\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.8295  -8.2815  -3.6443  ...  -10.1370  -9.7288 -10.2691\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 3\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5366 -5.6469 -3.9442  ...  -8.6268 -8.2512 -8.7509\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4973 -4.7878 -4.4031  ...  -8.5348 -8.0928 -8.4903\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 241\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5904 -4.4384 -4.9923  ...  -8.5368 -8.1328 -8.5021\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.6270  -1.1985  -5.2103  ...   -9.4051  -9.0564  -9.3551\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.3106  -8.4405  -0.5017  ...  -10.3976  -9.9372 -10.2566\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8746  -5.6129  -2.3708  ...   -8.7985  -8.5812  -8.9962\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8056  -4.0270  -3.4950  ...   -8.7571  -8.4668  -9.0103\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 732\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -8.8035  -3.6675  -4.3139  ...   -8.7144  -8.3744  -8.8651\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.9155  -0.7350  -5.0085  ...   -9.7030  -9.3990  -9.7279\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-10.2636  -9.7735  -0.6349  ...  -10.3693  -9.8941 -10.2163\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 14\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4966 -7.1190 -2.6085  ...  -8.5025 -8.0715 -8.5594\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 15\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.4452 -5.8374 -3.2935  ...  -8.4542 -7.9229 -8.4373\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 42\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3441 -5.4207 -3.9760  ...  -8.3621 -7.8335 -8.2893\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 131\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.3881 -4.9085 -4.2760  ...  -8.3068 -7.8529 -8.3053\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 87\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.2917 -4.6640 -5.2528  ...  -8.1832 -7.7996 -8.3227\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7962 -1.5664 -4.6695  ...  -8.6409 -8.2295 -8.6334\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output\n",
      "Variable containing:\n",
      " -9.9500  -8.7847  -1.3075  ...  -10.0542  -9.5885  -9.9483\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 77\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6691 -6.0952 -3.1320  ...  -8.6784 -8.2922 -8.9006\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5536 -4.5997 -4.2770  ...  -8.5518 -8.1880 -8.8089\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 11\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.6701 -3.8171 -5.1186  ...  -8.5051 -8.1829 -8.7049\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.4386  -1.0081  -5.6001  ...   -9.2227  -8.8882  -9.2901\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7983  -8.2487  -1.7464  ...   -9.9461  -9.4894  -9.8424\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 130\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7290 -6.1530 -3.9635  ...  -8.7314 -8.5151 -9.0059\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 78\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.5291 -4.4013 -4.8771  ...  -8.5524 -8.2903 -8.8521\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 329\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      "-8.7400 -3.7219 -5.4152  ...  -8.6581 -8.3169 -8.7638\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 4\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n",
      "decoder_output\n",
      "Variable containing:\n",
      " -9.7930  -0.6557  -6.1780  ...   -9.6038  -9.2900  -9.6517\n",
      "[torch.cuda.FloatTensor of size 1x2925 (GPU 0)]\n",
      "\n",
      "target_variable[di]\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e6d9fc7e1a32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-6d4793cf183b>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_variable, target_variable, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-8b05918766f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snakes/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/snakes/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> elle apprend a jouer du piano .\n",
      "= she is learning the piano .\n",
      "< she is learning the piano . <EOS>\n",
      "\n",
      "> elle coud une robe .\n",
      "= she is sewing a dress .\n",
      "< she is knitting in dress . <EOS>\n",
      "\n",
      "> il sait jouer de la guitare .\n",
      "= he is able to play the guitar .\n",
      "< he is eager to the the . <EOS>\n",
      "\n",
      "> je suppose que c est ton pere .\n",
      "= i m assuming this is your father .\n",
      "< i m assuming this is your father . <EOS>\n",
      "\n",
      "> je n ecarte pas cette possibilite .\n",
      "= i m not discounting that possibility .\n",
      "< i m not that that girl . <EOS>\n",
      "\n",
      "> nous sommes en train de lire .\n",
      "= we re reading .\n",
      "< we re reading . <EOS>\n",
      "\n",
      "> vous reagissez de maniere excessive .\n",
      "= you re overreacting .\n",
      "< you re overreacting . <EOS>\n",
      "\n",
      "> je ne tiens pas en place .\n",
      "= i m restless .\n",
      "< i m not in . <EOS>\n",
      "\n",
      "> nous sommes en retard .\n",
      "= we are late .\n",
      "< we re late . <EOS>\n",
      "\n",
      "> vous n etes pas comme moi .\n",
      "= you re not like me .\n",
      "< you re not like me . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Attention\n",
    "---------------------\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable\n",
    "outputs. Because it is used to weight specific encoder outputs of the\n",
    "input sequence, we can imagine looking where the network is focused most\n",
    "at each time step.\n",
    "\n",
    "You could simply run ``plt.matshow(attentions)`` to see attention output\n",
    "displayed as a matrix, with the columns being input steps and rows being\n",
    "output steps:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes\n",
    "and labels:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "=========\n",
    "\n",
    "-  Try with a different dataset\n",
    "\n",
    "   -  Another language pair\n",
    "   -  Human → Machine (e.g. IOT commands)\n",
    "   -  Chat → Response\n",
    "   -  Question → Answer\n",
    "\n",
    "-  Replace the embeddings with pre-trained word embeddings such as word2vec or\n",
    "   GloVe\n",
    "-  Try with more layers, more hidden units, and more sentences. Compare\n",
    "   the training time and results.\n",
    "-  If you use a translation file where pairs have two of the same phrase\n",
    "   (``I am test \\t I am test``), you can use this as an autoencoder. Try\n",
    "   this:\n",
    "\n",
    "   -  Train as an autoencoder\n",
    "   -  Save only the Encoder network\n",
    "   -  Train a new Decoder for translation from there\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
